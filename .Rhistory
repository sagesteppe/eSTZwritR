# we need a set of cities for cartography purposes, we want the big cities, or at least
# moderately sized cities which show up OK.
setwd('~/Documents/assoRted/eSTZwritR')
cities <- read.csv('./data-raw/simplemaps_uscities_basicv1.79/uscities.csv') |>
sf::st_as_sf(coords = c('lng', 'lat'), crs = 4326) |>
select(city, state_id, county_name, population) |>
# only one city per county. regardless of county size.
group_by(state_id, county_name) |>
slice_max(population, n = 1)
ggplot(data = cities) +
geom_sf()
# now some more advanced filtering. Only one city per 50 miles in distance,
# we use this to get rid of suburbs.
cit_buf <- sf::st_transform(cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(cities, 5070), cit_buf)
keep <- cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
rm(ints, investigate)
# from each of these vectors, select the city with the largest population.
subbr <- function(x){
subset <- cities[unlist(x), ]
out <- subset[which.max(subset$population),]
return(out)
}
out <- lapply(unique_investigations, subbr) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)  # remove the repeated cities
# Now only up to 10 cities per state.
catrographic_cities <- out |>
group_by(state_id) |>
slice_max(population, n = 8) |>
sf::st_transform(4326)
ggplot(data = catrographic_cities) +
geom_sf()
#######################################################################
# now repeat the process one more time, we have a couple oddities that
# came through on corner cases that should be easily fixed with fewer intercepts #
ints <- sf::st_intersects( sf::st_transform(cities, 5070), cit_buf)
View(ints)
ints <- sf::st_intersects(sf::st_transform(cities, 5070), cit_buf)
cit_buf <- sf::st_transform(catrographic_cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(catrographic_cities, 5070), cit_buf)
View(ints)
ints[[17]]
View(catrographic_cities)
out <- lapply(ints, subbr) |>
dplyr::bind_rows() |>
distinct(.keep_all = TRUE)
View(out)
catrographic_cities <- lapply(ints, subbr) |>
dplyr::bind_rows() |>
distinct(.keep_all = TRUE)
sf::st_write(catrographic_cities, "inst/extdata/Cartographic_cities.gpkg")
sf::st_write(catrographic_cities, "inst/extdata/Cartographic_cities.gpkg", append = F)
rm(subbr, keep, unique_investigations, cities, out)
library(sf)
library(tidyverse)
# we need a set of cities for cartography purposes, we want the big cities, or at least
# moderately sized cities which show up OK.
setwd('~/Documents/assoRted/eSTZwritR')
cities <- read.csv('./data-raw/simplemaps_uscities_basicv1.79/uscities.csv') |>
sf::st_as_sf(coords = c('lng', 'lat'), crs = 4326) |>
select(city, state_id, county_name, population) |>
# only one city per county. regardless of county size.
group_by(state_id, county_name) |>
slice_max(population, n = 1)
ggplot(data = cities) +
geom_sf()
# now some more advanced filtering. Only one city per 50 miles in distance,
# we use this to get rid of suburbs.
cit_buf <- sf::st_transform(cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(cities, 5070), cit_buf)
keep <- cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
rm(ints, investigate)
# from each of these vectors, select the city with the largest population.
subbr <- function(x){
subset <- cities[unlist(x), ]
out <- subset[which.max(subset$population),]
return(out)
}
out <- lapply(unique_investigations, subbr) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)  # remove the repeated cities
# Now only up to 10 cities per state.
catrographic_cities <- out |>
group_by(state_id) |>
slice_max(population, n = 8) |>
sf::st_transform(4326)
ggplot(data = catrographic_cities) +
geom_sf()
#######################################################################
# now repeat the process one more time, we have a couple oddities that
# came through on corner cases that should be easily fixed with fewer intercepts #
cit_buf <- sf::st_transform(catrographic_cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(catrographic_cities, 5070), cit_buf)
keep <- catrographic_cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
catrographic_cities <- lapply(ints, subbr) |>
dplyr::bind_rows() |>
distinct(.keep_all = TRUE)
sf::st_write(catrographic_cities, "inst/extdata/Cartographic_cities.gpkg", append = F)
rm(subbr, keep, unique_investigations, cities, out)
catrographic_cities <- lapply(ints, subbr) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)
library(sf)
library(tidyverse)
# we need a set of cities for cartography purposes, we want the big cities, or at least
# moderately sized cities which show up OK.
setwd('~/Documents/assoRted/eSTZwritR')
cities <- read.csv('./data-raw/simplemaps_uscities_basicv1.79/uscities.csv') |>
sf::st_as_sf(coords = c('lng', 'lat'), crs = 4326) |>
select(city, state_id, county_name, population) |>
# only one city per county. regardless of county size.
group_by(state_id, county_name) |>
slice_max(population, n = 1)
ggplot(data = cities) +
geom_sf()
# now some more advanced filtering. Only one city per 50 miles in distance,
# we use this to get rid of suburbs.
cit_buf <- sf::st_transform(cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(cities, 5070), cit_buf)
keep <- cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
rm(ints, investigate)
# from each of these vectors, select the city with the largest population.
subbr <- function(x){
subset <- cities[unlist(x), ]
out <- subset[which.max(subset$population),]
return(out)
}
out <- lapply(unique_investigations, subbr) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)  # remove the repeated cities
# Now only up to 10 cities per state.
catrographic_cities <- out |>
group_by(state_id) |>
slice_max(population, n = 8) |>
sf::st_transform(4326)
ggplot(data = catrographic_cities) +
geom_sf()
#######################################################################
# now repeat the process one more time, we have a couple oddities that
# came through on corner cases that should be easily fixed with fewer intercepts #
cit_buf <- sf::st_transform(catrographic_cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(catrographic_cities, 5070), cit_buf)
keep <- catrographic_cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
catrographic_cities <- lapply(ints, subbr) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)
sf::st_write(catrographic_cities, "inst/extdata/Cartographic_cities.gpkg", append = F)
rm(subbr, keep, unique_investigations, cities, out)
View(catrographic_cities)
library(sf)
library(tidyverse)
# we need a set of cities for cartography purposes, we want the big cities, or at least
# moderately sized cities which show up OK.
setwd('~/Documents/assoRted/eSTZwritR')
cities <- read.csv('./data-raw/simplemaps_uscities_basicv1.79/uscities.csv') |>
sf::st_as_sf(coords = c('lng', 'lat'), crs = 4326) |>
select(city, state_id, county_name, population) |>
# only one city per county. regardless of county size.
group_by(state_id, county_name) |>
slice_max(population, n = 1)
ggplot(data = cities) +
geom_sf()
# now some more advanced filtering. Only one city per 50 miles in distance,
# we use this to get rid of suburbs.
cit_buf <- sf::st_transform(cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(cities, 5070), cit_buf)
keep <- cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
rm(ints, investigate)
# from each of these vectors, select the city with the largest population.
subbr <- function(x){
subset <- cities[unlist(x), ]
out <- subset[which.max(subset$population),]
return(out)
}
out <- lapply(unique_investigations, subbr) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)  # remove the repeated cities
# Now only up to 10 cities per state.
catrographic_cities <- out |>
group_by(state_id) |>
slice_max(population, n = 8) |>
sf::st_transform(4326)
ggplot(data = catrographic_cities) +
geom_sf()
#######################################################################
# now repeat the process one more time, we have a couple oddities that
# came through on corner cases that should be easily fixed with fewer intercepts #
cit_buf <- sf::st_transform(catrographic_cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(catrographic_cities, 5070), cit_buf)
keep <- catrographic_cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
catrographic_cities <- lapply(ints, subbr) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)
View(catrographic_cities)
cit_buf <- sf::st_transform(catrographic_cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(catrographic_cities, 5070), cit_buf)
View(ints)
ints[[30]]
keep <- catrographic_cities[ unlist(ints[lengths(ints) == 1]), ]
View(keep)
subbr <- function(x, y){
subset <- y[unlist(x), ]
out <- subset[which.max(subset$population),]
return(out)
}
catrographic_cities <- lapply(ints, subbr, y = catrographic_cities) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)
ggplot(data = catrographic_cities) +
geom_sf()
sf::st_write(catrographic_cities, "inst/extdata/Cartographic_cities.gpkg", append = F)
library(sf)
library(tidyverse)
# we need a set of cities for cartography purposes, we want the big cities, or at least
# moderately sized cities which show up OK.
setwd('~/Documents/assoRted/eSTZwritR')
cities <- read.csv('./data-raw/simplemaps_uscities_basicv1.79/uscities.csv') |>
sf::st_as_sf(coords = c('lng', 'lat'), crs = 4326) |>
select(city, state_id, county_name, population) |>
# only one city per county. regardless of county size.
group_by(state_id, county_name) |>
slice_max(population, n = 1)
ggplot(data = cities) +
geom_sf()
# now some more advanced filtering. Only one city per 50 miles in distance,
# we use this to get rid of suburbs.
cit_buf <- sf::st_transform(cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(cities, 5070), cit_buf)
keep <- cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
rm(ints, investigate)
# from each of these vectors, select the city with the largest population.
subbr <- function(x, y){
subset <- y[unlist(x), ]
out <- subset[which.max(subset$population),]
return(out)
}
out <- lapply(unique_investigations, subbr) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)  # remove the repeated cities
out <- lapply(unique_investigations, subbr, y = cities) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)  # remove the repeated cities
# Now only up to 10 cities per state.
catrographic_cities <- out |>
group_by(state_id) |>
slice_max(population, n = 8) |>
sf::st_transform(4326)
ggplot(data = catrographic_cities) +
geom_sf()
cit_buf <- sf::st_transform(catrographic_cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(catrographic_cities, 5070), cit_buf)
keep <- catrographic_cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
catrographic_cities <- lapply(ints, subbr, y = catrographic_cities) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)
sf::st_write(catrographic_cities, "inst/extdata/Cartographic_cities.gpkg", append = F)
View(catrographic_cities)
library(sf)
library(tidyverse)
# we need a set of cities for cartography purposes, we want the big cities, or at least
# moderately sized cities which show up OK.
setwd('~/Documents/assoRted/eSTZwritR')
cities <- read.csv('./data-raw/simplemaps_uscities_basicv1.79/uscities.csv') |>
sf::st_as_sf(coords = c('lng', 'lat'), crs = 4326) |>
select(city, state_id, county_name, population) |>
# only one city per county. regardless of county size.
group_by(state_id, county_name) |>
slice_max(population, n = 1)
ggplot(data = cities) +
geom_sf()
# now some more advanced filtering. Only one city per 50 miles in distance,
# we use this to get rid of suburbs.
cit_buf <- sf::st_transform(cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(cities, 5070), cit_buf)
keep <- cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
rm(ints, investigate)
# from each of these vectors, select the city with the largest population.
subbr <- function(x, y){
subset <- y[unlist(x), ]
out <- subset[which.max(subset$population),]
return(out)
}
out <- lapply(unique_investigations, subbr, y = cities) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)  # remove the repeated cities
# Now only up to 10 cities per state.
catrographic_cities <- out |>
group_by(state_id) |>
slice_max(population, n = 8) |>
sf::st_transform(4326)
ggplot(data = catrographic_cities) +
geom_sf()
#######################################################################
# now repeat the process one more time, we have a couple oddities that
# came through on corner cases that should be easily fixed with fewer intercepts #
cit_buf <- sf::st_transform(catrographic_cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(catrographic_cities, 5070), cit_buf)
keep <- catrographic_cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
catrographic_cities <- lapply(ints, subbr, y = catrographic_cities) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE) |>
select(city, state_id)
sf::st_write(catrographic_cities, "inst/extdata/Cartographic_cities.gpkg", append = F)
rm(subbr, keep, unique_investigations, cities, out)
rm(subbr, keep, unique_investigations, cities, out, cit_buf, ints, investigate)
rm(subbr, keep, unique_investigations, cities, out, cit_buf, ints, investigate, catrographic_cities)
catrographic_cities
library(sf)
library(tidyverse)
# we need a set of cities for cartography purposes, we want the big cities, or at least
# moderately sized cities which show up OK.
setwd('~/Documents/assoRted/eSTZwritR')
cities <- read.csv('./data-raw/simplemaps_uscities_basicv1.79/uscities.csv') |>
sf::st_as_sf(coords = c('lng', 'lat'), crs = 4326) |>
select(city, state_id, county_name, population) |>
# only one city per county. regardless of county size.
group_by(state_id, county_name) |>
slice_max(population, n = 1)
ggplot(data = cities) +
geom_sf()
# now some more advanced filtering. Only one city per 50 miles in distance,
# we use this to get rid of suburbs.
cit_buf <- sf::st_transform(cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(cities, 5070), cit_buf)
keep <- cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
rm(ints, investigate)
# from each of these vectors, select the city with the largest population.
subbr <- function(x, y){
subset <- y[unlist(x), ]
out <- subset[which.max(subset$population),]
return(out)
}
out <- lapply(unique_investigations, subbr, y = cities) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)  # remove the repeated cities
# Now only up to 10 cities per state.
catrographic_cities <- out |>
group_by(state_id) |>
slice_max(population, n = 8) |>
sf::st_transform(4326)
ggplot(data = catrographic_cities) +
geom_sf()
#######################################################################
# now repeat the process one more time, we have a couple oddities that
# came through on corner cases that should be easily fixed with fewer intercepts #
cit_buf <- sf::st_transform(catrographic_cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(catrographic_cities, 5070), cit_buf)
keep <- catrographic_cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
catrographic_cities <- lapply(ints, subbr, y = catrographic_cities) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE) |>
select(city, state_id)
View(catrographic_cities)
catrographic_cities <- lapply(ints, subbr, y = catrographic_cities) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE) |>
select(City = city, State = state_id)
library(sf)
library(tidyverse)
# we need a set of cities for cartography purposes, we want the big cities, or at least
# moderately sized cities which show up OK.
setwd('~/Documents/assoRted/eSTZwritR')
cities <- read.csv('./data-raw/simplemaps_uscities_basicv1.79/uscities.csv') |>
sf::st_as_sf(coords = c('lng', 'lat'), crs = 4326) |>
select(city, state_id, county_name, population) |>
# only one city per county. regardless of county size.
group_by(state_id, county_name) |>
slice_max(population, n = 1)
ggplot(data = cities) +
geom_sf()
# now some more advanced filtering. Only one city per 50 miles in distance,
# we use this to get rid of suburbs.
cit_buf <- sf::st_transform(cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(cities, 5070), cit_buf)
keep <- cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
rm(ints, investigate)
# from each of these vectors, select the city with the largest population.
subbr <- function(x, y){
subset <- y[unlist(x), ]
out <- subset[which.max(subset$population),]
return(out)
}
out <- lapply(unique_investigations, subbr, y = cities) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)  # remove the repeated cities
# Now only up to 10 cities per state.
catrographic_cities <- out |>
group_by(state_id) |>
slice_max(population, n = 8) |>
sf::st_transform(4326)
ggplot(data = catrographic_cities) +
geom_sf()
#######################################################################
# now repeat the process one more time, we have a couple oddities that
# came through on corner cases that should be easily fixed with fewer intercepts #
cit_buf <- sf::st_transform(catrographic_cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(catrographic_cities, 5070), cit_buf)
keep <- catrographic_cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
catrographic_cities <- lapply(ints, subbr, y = catrographic_cities) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE) |>
select(City = city, State = state_id)
sf::st_write(catrographic_cities, "inst/extdata/Cartographic_cities.gpkg", append = F)
rm(subbr, keep, unique_investigations, cities, out, cit_buf, ints, investigate, catrographic_cities)
sf::st_write(catrographic_cities, "inst/extdata/Carto_cities.gpkg", append = F)
library(sf)
library(tidyverse)
# we need a set of cities for cartography purposes, we want the big cities, or at least
# moderately sized cities which show up OK.
setwd('~/Documents/assoRted/eSTZwritR')
cities <- read.csv('./data-raw/simplemaps_uscities_basicv1.79/uscities.csv') |>
sf::st_as_sf(coords = c('lng', 'lat'), crs = 4326) |>
select(city, state_id, county_name, population) |>
# only one city per county. regardless of county size.
group_by(state_id, county_name) |>
slice_max(population, n = 1)
ggplot(data = cities) +
geom_sf()
# now some more advanced filtering. Only one city per 50 miles in distance,
# we use this to get rid of suburbs.
cit_buf <- sf::st_transform(cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(cities, 5070), cit_buf)
keep <- cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
rm(ints, investigate)
# from each of these vectors, select the city with the largest population.
subbr <- function(x, y){
subset <- y[unlist(x), ]
out <- subset[which.max(subset$population),]
return(out)
}
out <- lapply(unique_investigations, subbr, y = cities) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE)  # remove the repeated cities
# Now only up to 10 cities per state.
catrographic_cities <- out |>
group_by(state_id) |>
slice_max(population, n = 8) |>
sf::st_transform(4326)
ggplot(data = catrographic_cities) +
geom_sf()
#######################################################################
# now repeat the process one more time, we have a couple oddities that
# came through on corner cases that should be easily fixed with fewer intercepts #
cit_buf <- sf::st_transform(catrographic_cities, 5070) |>
sf::st_buffer(80468)
ints <- sf::st_intersects( sf::st_transform(catrographic_cities, 5070), cit_buf)
keep <- catrographic_cities[ unlist(ints[lengths(ints) == 1]), ]
investigate <-ints[lengths(ints) > 1]
unique_investigations <- investigate[!duplicated(lapply(investigate, sort))]
catrographic_cities <- lapply(ints, subbr, y = catrographic_cities) |>
dplyr::bind_rows(keep) |>
distinct(.keep_all = TRUE) |>
select(City = city, State = state_id)
sf::st_write(catrographic_cities, "inst/extdata/Carto_cities.gpkg", append = F)
rm(subbr, keep, unique_investigations, cities, out, cit_buf, ints, investigate, catrographic_cities)
system.file('eSTZwritR')
library(eSTZwritR)
system.file('eSTZwritR')
library(eSTZwritR)
# install.packages('devtools')
devtools::install_github('sagesteppe/eSTZwritR')
